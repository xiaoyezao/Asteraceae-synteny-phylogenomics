{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# before we start drimm-synteny anaslysis, we need to generate synOG table using genespace_parser()\n",
    "    refer to genespace_parser.ipynb\n",
    "    be carefull about how speciese name and gene name are connected (\"@\" or \"_\")\n",
    "1. use “processOrthofinder_tao.py” to process the genespace pangenome output to get “drimm.sequence” —> be careful about the copy_ratio\n",
    "\n",
    "2. use “drimm-synteny” on windows to built up drimm blocks. —→ this current only works on windows, we can use it on unix with Wine software, but on Merian, I have issues with X11 library which can not find by Wine\n",
    "\n",
    "3. use “processDrimm_tao.py” on the outputs from last step to obtain final blocks for IAGS\n",
    "\n",
    "4. use IAGS to construct ancestral genomes; I also tried mgra (by index and reformat the blocks) but it doesn’t work.\n",
    "    \n",
    "from here we can use either iags <option -ff> or grimm to calculate genome shuffling event’s:\n",
    "    \n",
    "5. ***a***) use “standardize_drimmBlocks.py” to index and reformat the drimm genomes including ancestors and also extent genomes; then use grimm to characterise genome rearrangements; ***b***) use iags to calculate directly\n",
    "\n",
    "6. plotting and interpretation using iags (option -p); before this we need use “processGenenumber_tao.py” to generate the data needed by iags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dependencies ready\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils import processLCSAndFirstFilter_2sp as plff\n",
    "from utils import processFinalFilter_2sp as pff\n",
    "import shutil\n",
    "from processDrimm_tao_2sp import readSequence,prepare_dir,write_raw_blocks,processDrimm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules_paper import prepare_OG,prepare_meta,make_comBed,combed_parser,grimmBlock_parser,getFilterSequence,getAllSequence,outSequence,standarlize_drimmblocks,get_block_info,get_chromosome_info\n",
    "from parse_genespaceBED_for_drimmBED_paper import make_index,make_drimmBED,make_genome_meta,make_chromosome_meta,get_chromosome_lenght,parse_genespaceBED_for_drimmBED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input data ready\n",
    "sp='sp46'\n",
    "index_file = \"/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/Smar.EM05.v1.genome.fa.fai\"\n",
    "\n",
    "workdir = \"/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/workdir\"\n",
    "BED_folder = \"/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/\"\n",
    "if not workdir[-1] == \"/\": workdir += \"/\"\n",
    "if not BED_folder[-1] == \"/\": BED_folder += \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/workdir/bed/ exists, let's generate bed file in this floder\n",
      "/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/workdir/bed/sp03v5.bed exists!\n",
      "/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/workdir/bed/sp46.bed exists!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor file in os.listdir(BED_folder):\\n    if file.endswith(\".bed\"):\\n        genome_name = os.path.splitext(file)[0]\\n        bed = BED_folder + file\\n        new_bed = new_bed_path + genome_name + \".bed\"\\n        if not os.path.exists(new_bed):\\n            print(new_bed + \" is new, adding to database ...\")\\n            chr_info,df = parse_genespaceBED_for_drimmBED(bed,DIC)\\n            df.to_csv(new_bed, header=None, index=None, sep=\\'\\t\\')\\n            chr_size = [\"_\".join(c.split(\"_\")[0:-1]) for c in chr_info] # remove the chr length (e.g., \"sp03v1@a11_1_1679_69615488\")\\n            list_ = [genome_name] + chr_size\\n            chromosome_meta_dict.append(list_)\\n            #f.write(genome_name + \"\\t\" + \"\\t\".join(chr_size) + \"\\n\")\\n        else:\\n            print(new_bed + \" exists, let\\'s just make chromosome_meta!\")\\n            chr_info,df = parse_genespaceBED_for_drimmBED(bed,DIC)\\n            chr_size = [\"_\".join(c.split(\"_\")[0:-1]) for c in chr_info] # remove the chr length (e.g., \"sp03v1@a11_1_1679_69615488\")\\n            list_ = [genome_name] + chr_size\\n            chromosome_meta_dict.append(list_)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step0, first let's prepare bed and meta data\n",
    "## make index file\n",
    "df_index = make_index(sp,index_file) #your genome index and genome name you want to use\n",
    "\n",
    "## make bed, genome_meta, chromosome_meta\n",
    "DIC = {f\"{row['sp']}@{row['chr']}\": row['length'] for _, row in df_index.iterrows()}\n",
    "bed_dir = workdir + \"bed/\"\n",
    "if not os.path.exists(bed_dir):\n",
    "    os.makedirs(bed_dir)\n",
    "    make_drimmBED(BED_folder, DIC, bed_dir)\n",
    "else:\n",
    "    print(bed_dir + \" exists, let's generate bed file in this floder\")\n",
    "    make_drimmBED(BED_folder, DIC, bed_dir)\n",
    "\n",
    "'''\n",
    "for file in os.listdir(BED_folder):\n",
    "    if file.endswith(\".bed\"):\n",
    "        genome_name = os.path.splitext(file)[0]\n",
    "        bed = BED_folder + file\n",
    "        new_bed = new_bed_path + genome_name + \".bed\"\n",
    "        if not os.path.exists(new_bed):\n",
    "            print(new_bed + \" is new, adding to database ...\")\n",
    "            chr_info,df = parse_genespaceBED_for_drimmBED(bed,DIC)\n",
    "            df.to_csv(new_bed, header=None, index=None, sep='\\t')\n",
    "            chr_size = [\"_\".join(c.split(\"_\")[0:-1]) for c in chr_info] # remove the chr length (e.g., \"sp03v1@a11_1_1679_69615488\")\n",
    "            list_ = [genome_name] + chr_size\n",
    "            chromosome_meta_dict.append(list_)\n",
    "            #f.write(genome_name + \"\\t\" + \"\\t\".join(chr_size) + \"\\n\")\n",
    "        else:\n",
    "            print(new_bed + \" exists, let's just make chromosome_meta!\")\n",
    "            chr_info,df = parse_genespaceBED_for_drimmBED(bed,DIC)\n",
    "            chr_size = [\"_\".join(c.split(\"_\")[0:-1]) for c in chr_info] # remove the chr length (e.g., \"sp03v1@a11_1_1679_69615488\")\n",
    "            list_ = [genome_name] + chr_size\n",
    "            chromosome_meta_dict.append(list_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pgID</th>\n",
       "      <th>interpChr</th>\n",
       "      <th>repGene</th>\n",
       "      <th>sp46</th>\n",
       "      <th>sp03v5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a1</td>\n",
       "      <td>Alap.ptg000007l.g159.t1</td>\n",
       "      <td>sp46@Smar01g000670.1</td>\n",
       "      <td>sp03v5@Alap.ptg000007l.g159.t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a1</td>\n",
       "      <td>Alap.ptg000007l.g160.t1</td>\n",
       "      <td>sp46@Smar01g000680.1</td>\n",
       "      <td>sp03v5@Alap.ptg000007l.g160.t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>a1</td>\n",
       "      <td>Alap.ptg000007l.g161.t1</td>\n",
       "      <td>sp46@Smar01g000690.1</td>\n",
       "      <td>sp03v5@Alap.ptg000007l.g161.t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>a1</td>\n",
       "      <td>Alap.ptg000007l.g162.t1</td>\n",
       "      <td>sp46@Smar01g000700.1</td>\n",
       "      <td>sp03v5@Alap.ptg000007l.g162.t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>a1</td>\n",
       "      <td>Alap.ptg000007l.g163.t1</td>\n",
       "      <td>sp46@Smar01g000710.1</td>\n",
       "      <td>sp03v5@Alap.ptg000007l.g163.t1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pgID interpChr                  repGene                  sp46  \\\n",
       "0    1        a1  Alap.ptg000007l.g159.t1  sp46@Smar01g000670.1   \n",
       "1    2        a1  Alap.ptg000007l.g160.t1  sp46@Smar01g000680.1   \n",
       "2    4        a1  Alap.ptg000007l.g161.t1  sp46@Smar01g000690.1   \n",
       "3    9        a1  Alap.ptg000007l.g162.t1  sp46@Smar01g000700.1   \n",
       "4   10        a1  Alap.ptg000007l.g163.t1  sp46@Smar01g000710.1   \n",
       "\n",
       "                           sp03v5  \n",
       "0  sp03v5@Alap.ptg000007l.g159.t1  \n",
       "1  sp03v5@Alap.ptg000007l.g160.t1  \n",
       "2  sp03v5@Alap.ptg000007l.g161.t1  \n",
       "3  sp03v5@Alap.ptg000007l.g162.t1  \n",
       "4  sp03v5@Alap.ptg000007l.g163.t1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step1 process synOG\n",
    "## get dependent info ready, read in synOG table\n",
    "from processOrthofinder_tao import get_group_dir,get_final_group,main\n",
    "\n",
    "## read in synOG table and adjust name\n",
    "orthogroups = \"/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/2_analysis/1_genespace/run30/pangenome_sp03v5_synOG_2sp_syn.txt\"\n",
    "## be careful with this orthogroups table; in terms of the name \"sp03v5\" vs \"\"sp03_v5\"\", and \"sp03v5@gene1\" vs \"sp03v5_gene1\"; we need to make this consistent in genespace_parser()\n",
    "ortho = pd.read_csv(orthogroups, sep='\\t', dtype = str, keep_default_na=False)\n",
    "ortho2 = ortho[ortho[\"interpChr\"] != \"\"]\n",
    "\n",
    "ortho2.rename(columns={'sp03_v5': 'sp03v5', 'sp03_v1': 'sp03v1'}, inplace=True)\n",
    "ortho2['sp03v5'] = ortho2['sp03v5'].str.replace('sp03_v5@', 'sp03v5@')\n",
    "ortho2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sp03v5', 'sp03v5@a11_1_1679', 'sp03v5@a5_2_1622', 'sp03v5@a12_3_1595', 'sp03v5@b11_4_1586', 'sp03v5@c12_5_1441', 'sp03v5@c11_6_1341', 'sp03v5@c13_7_1301', 'sp03v5@b13_8_1246', 'sp03v5@a13_9_1243', 'sp03v5@a10_10_1189', 'sp03v5@b12_11_1137', 'sp03v5@c14_12_1116', 'sp03v5@a4_13_1044', 'sp03v5@b6_14_1044', 'sp03v5@a14_15_1031', 'sp03v5@c5_16_1030', 'sp03v5@c4_17_964', 'sp03v5@a2_18_931', 'sp03v5@b5_19_931', 'sp03v5@a7_20_917', 'sp03v5@b10_21_917', 'sp03v5@b4_22_903', 'sp03v5@c6_23_874', 'sp03v5@a1_24_861', 'sp03v5@b7_25_836', 'sp03v5@b2_26_822', 'sp03v5@c2_27_786', 'sp03v5@c7_28_743', 'sp03v5@c10_29_728', 'sp03v5@c9_30_689', 'sp03v5@a3_31_679', 'sp03v5@b1_32_677', 'sp03v5@c8_33_664', 'sp03v5@a6_34_634', 'sp03v5@b14_35_614', 'sp03v5@a9_36_577', 'sp03v5@b8_37_577', 'sp03v5@c15_38_565', 'sp03v5@c1_39_515', 'sp03v5@b3_40_475', 'sp03v5@c3_41_464', 'sp03v5@a8_42_454', 'sp03v5@b9_43_410', 'sp03v5@a15_44_266', 'sp03v5@b15_45_110'], ['sp46', 'sp46@chr01_1_4688', 'sp46@chr05_2_4559', 'sp46@chr02_3_4224', 'sp46@chr04_4_4180', 'sp46@chr03_5_3861', 'sp46@chr06_6_3453', 'sp46@chr07_7_3166', 'sp46@chr11_8_3013', 'sp46@chr10_9_2993', 'sp46@chr12_10_2861', 'sp46@chr08_11_2739', 'sp46@chr13_12_2623', 'sp46@chr09_13_2583', 'sp46@chr14_14_2201', 'sp46@chr16_15_2125', 'sp46@chr15_16_2109', 'sp46@chr17_17_2076', 'sp46@ctg000560_18_12', 'sp46@ctg000060_19_9', 'sp46@ctg000510_20_8', 'sp46@ctg000020_21_7', 'sp46@ctg000520_22_7', 'sp46@ctg000000_23_6', 'sp46@ctg000130_24_6', 'sp46@ctg000070_25_5', 'sp46@ctg000240_26_5', 'sp46@ctg000230_27_4', 'sp46@ctg000400_28_4', 'sp46@ctg000480_29_4', 'sp46@ctg000500_30_3', 'sp46@ctg000580_31_3', 'sp46@ctg000050_32_2', 'sp46@ctg000460_33_2', 'sp46@ctg000470_34_2', 'sp46@ctg000490_35_2', 'sp46@ctg000540_36_2', 'sp46@ctg000550_37_2', 'sp46@ctg000570_38_2', 'sp46@ctg000410_39_1']]\n",
      "sp46 seems already done, please check!\n"
     ]
    }
   ],
   "source": [
    "## process synOG table, call pairwise orthologs for given ref-target pair\n",
    "##target = [\"sp28\",\"sp24\",\"sp43\",\"sp44\",\"sp18\",\"sp34\",\"sp14\",\"sp10\",\"sp08\",\"sp35\",\"sp05a\",\"sp39\",\"sp37\",\"sp11\",\"sp13\",\"sp22\",\"sp21\",\"sp29\",\"sp30\",\"sp03_v5\",\"sp03_v1\",\"sp03\",\"sp41\",\"sp07\",\"sp15\"]\n",
    "target = [\"sp46\"]\n",
    "reference = \"sp03v5\"\n",
    "OG_type = \"synOG\" # always check the varable \"sp_ratio\"\n",
    "\n",
    "genome_meta = make_genome_meta(\"sp46\",1,17)\n",
    "chromosome_meta = make_chromosome_meta(BED_folder,DIC)\n",
    "print(chromosome_meta)\n",
    "\n",
    "outdir = workdir + \"out1\"\n",
    "if outdir[-1] != \"/\": outdir += \"/\"\n",
    "if bed_dir[-1] != \"/\": bed_dir += \"/\"\n",
    "\n",
    "for species in target:\n",
    "    if not species == reference: \n",
    "        species_list = [reference, species]\n",
    "        subdir = outdir + species + \"/1_SynOG/\"\n",
    "        if not Path(subdir).exists():\n",
    "            os.makedirs(subdir)\n",
    "            sp,sp_ratio,sp_chr_number,long_chr_list,gff_list = prepare_meta(species_list,genome_meta,chromosome_meta,OG_type,bed_dir)\n",
    "            #print(sp)\n",
    "            #print(sp_chr_number)\n",
    "            print(gff_list,long_chr_list)\n",
    "            ortho3 = prepare_OG(ortho2,sp,OG_type)\n",
    "            group_dir = get_group_dir(ortho3,sp)\n",
    "            finalGroup = get_final_group(group_dir,sp_ratio)\n",
    "            main(bed_dir,subdir,group_dir,finalGroup,gff_list,long_chr_list)\n",
    "        else: print(species + \" seems already done, please check!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### Step2 perform drimm-synteny in windows\n",
    "1. transfer the data from last step to windows\n",
    "   #put the whole directory (e.g., genespace26) in C:\\Users\\fengtao\\Desktop\\drimm_batch\\\n",
    "2. double click the windows bat file \"drimm-synteny\"; the tool will loop the genomes in \"genespace26\" and perform calculation\n",
    "   \n",
    "   **input poped options:**\n",
    "     + The path of drimm.sequence <drimm.sequence>\n",
    "     + The output directory <.>\n",
    "     + cycleLengthThreshold controls the continuity of synteny blocks (default parameter is 20)\n",
    "     + dustThreshold controls the upper limit of gene family. The gene family will be filtered when homologous genes exceeding dustThreshold. For above example, target copy numbers are 2,4,2,2,2 in each species, then the dustThreshold is 13 (2+4+2+2+2+1)\n",
    "3. wait untill the calculations done, copy the results to MAC, and go ahead with next step\n",
    "\n",
    "A  ***drimm-synteny.bat*** file is like this:\n",
    ">\n",
    "> @echo off\n",
    ">\n",
    "> REM Loop through each subdirectory\n",
    "> for /d %%A in (\"C:\\Users\\fengtao\\Desktop\\drimm_batch\\genespace26\\*\") do (\n",
    "   >\n",
    "    > echo Entering directory: %%A\\2_DrimmRaw\\\n",
    "    >\n",
    "    > mkdir \"%%A\\2_DrimmRaw\\\"\n",
    "    >\n",
    "    > copy \"%%A\\1_SynOG\\drimm.sequence\" \"%%A\\2_DrimmRaw\\\"\n",
    "    >\n",
    "    > pushd \"%%A\\2_DrimmRaw\\\"\n",
    "    >\n",
    "    >\n",
    "    > echo inputs like this, modify accordingly: inputfile=drimm.sequence  outdir=.  cycleLengthThreshold=20  dustThreshold=5\n",
    "    >\n",
    "    >\n",
    "    > REM Run your executable tool with non-interactive inputs\n",
    "    >\n",
    "    > \"C:\\Users\\fengtao\\Desktop\\processDrimm\\drimm\\drimm\\bin\\Release\\netcoreapp3.1\\win-x64\\drimm.exe\"\n",
    "    >\n",
    "    > echo %%A done!\n",
    "    >\n",
    "    > popd\n",
    "> )\n",
    "> pause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/workdir/out1/sp46/\n",
      "288:1:chr_8 has 1 anchors, drop!\n",
      "318:1:chr_11 has 1 anchors, drop!\n",
      "512:1:chr_13 has 1 anchors, drop!\n",
      "85:1:chr_15 has 1 anchors, drop!\n",
      "72:1:chr_19 has 1 anchors, drop!\n",
      "636:1:chr_23 has 1 anchors, drop!\n",
      "109:1:chr_25 has 1 anchors, drop!\n",
      "69:1:chr_28 has 1 anchors, drop!\n",
      "52:1:chr_33 has 1 anchors, drop!\n",
      "52:2:chr_34 has 2 anchors, drop!\n",
      "56:1:chr_34 has 1 anchors, drop!\n",
      "56:2:chr_35 has 2 anchors, drop!\n",
      "66:1:chr_35 has 2 anchors, drop!\n",
      "723:1:chr_36 has 2 anchors, drop!\n",
      "48:1:chr_36 has 1 anchors, drop!\n",
      "48:2:chr_37 has 2 anchors, drop!\n",
      "770:1:chr_37 has 2 anchors, drop!\n",
      "770:2:chr_37 has 1 anchors, drop!\n",
      "226:1:chr_38 has 1 anchors, drop!\n",
      "430:1:chr_42 has 1 anchors, drop!\n",
      "257:1:chr_1 has 1 anchors, drop!\n",
      "298:1:chr_1 has 2 anchors, drop!\n",
      "297:1:chr_1 has 2 anchors, drop!\n",
      "664:1:chr_2 has 1 anchors, drop!\n",
      "553:1:chr_2 has 2 anchors, drop!\n",
      "498:1:chr_2 has 2 anchors, drop!\n",
      "24:1:chr_3 has 2 anchors, drop!\n",
      "260:1:chr_3 has 1 anchors, drop!\n",
      "685:1:chr_4 has 2 anchors, drop!\n",
      "480:1:chr_4 has 2 anchors, drop!\n",
      "213:1:chr_4 has 2 anchors, drop!\n",
      "637:1:chr_4 has 2 anchors, drop!\n",
      "579:1:chr_5 has 2 anchors, drop!\n",
      "594:1:chr_5 has 2 anchors, drop!\n",
      "589:1:chr_5 has 1 anchors, drop!\n",
      "80:1:chr_6 has 1 anchors, drop!\n",
      "335:1:chr_7 has 1 anchors, drop!\n",
      "348:1:chr_7 has 2 anchors, drop!\n",
      "514:2:chr_7 has 1 anchors, drop!\n",
      "137:1:chr_7 has 1 anchors, drop!\n",
      "783:1:chr_8 has 2 anchors, drop!\n",
      "408:1:chr_8 has 2 anchors, drop!\n",
      "322:1:chr_9 has 2 anchors, drop!\n",
      "699:1:chr_11 has 2 anchors, drop!\n",
      "780:2:chr_12 has 1 anchors, drop!\n",
      "774:1:chr_12 has 1 anchors, drop!\n",
      "630:1:chr_12 has 2 anchors, drop!\n",
      "789:2:chr_12 has 1 anchors, drop!\n",
      "311:1:chr_12 has 1 anchors, drop!\n",
      "714:1:chr_13 has 1 anchors, drop!\n",
      "709:1:chr_13 has 2 anchors, drop!\n",
      "190:1:chr_14 has 1 anchors, drop!\n",
      "801:1:chr_14 has 2 anchors, drop!\n",
      "365:1:chr_14 has 2 anchors, drop!\n",
      "743:1:chr_16 has 2 anchors, drop!\n",
      "777:2:chr_17 has 2 anchors, drop!\n",
      "479:1:chr_17 has 2 anchors, drop!\n",
      "481:1:chr_17 has 1 anchors, drop!\n",
      "347 has ratio 1:0, drop!\n",
      "339 has ratio 1:0, drop!\n",
      "349 has ratio 1:0, drop!\n",
      "351 has ratio 1:0, drop!\n",
      "372 has ratio 1:0, drop!\n",
      "801 has ratio 1:0, drop!\n",
      "371 has ratio 1:0, drop!\n",
      "370 has ratio 1:0, drop!\n",
      "369 has ratio 1:0, drop!\n",
      "367 has ratio 1:0, drop!\n",
      "363 has ratio 1:0, drop!\n",
      "360 has ratio 1:0, drop!\n",
      "358 has ratio 1:0, drop!\n",
      "579 has ratio 1:0, drop!\n",
      "355 has ratio 1:0, drop!\n",
      "354 has ratio 1:0, drop!\n",
      "352 has ratio 1:0, drop!\n",
      "327 has ratio 1:0, drop!\n",
      "414 has ratio 1:0, drop!\n",
      "373 has ratio 1:0, drop!\n",
      "326 has ratio 1:0, drop!\n",
      "324 has ratio 1:0, drop!\n",
      "296 has ratio 1:0, drop!\n",
      "295 has ratio 1:0, drop!\n",
      "294 has ratio 1:0, drop!\n",
      "291 has ratio 1:0, drop!\n",
      "481 has ratio 1:0, drop!\n",
      "299 has ratio 1:0, drop!\n",
      "289 has ratio 1:0, drop!\n",
      "287 has ratio 1:0, drop!\n",
      "284 has ratio 1:0, drop!\n",
      "283 has ratio 1:0, drop!\n",
      "282 has ratio 1:0, drop!\n",
      "281 has ratio 1:0, drop!\n",
      "300 has ratio 1:0, drop!\n",
      "302 has ratio 1:0, drop!\n",
      "321 has ratio 1:0, drop!\n",
      "319 has ratio 1:0, drop!\n",
      "317 has ratio 1:0, drop!\n",
      "774 has ratio 1:0, drop!\n",
      "316 has ratio 1:0, drop!\n",
      "630 has ratio 1:0, drop!\n",
      "315 has ratio 1:0, drop!\n",
      "314 has ratio 1:0, drop!\n",
      "313 has ratio 1:0, drop!\n",
      "312 has ratio 1:0, drop!\n",
      "310 has ratio 1:0, drop!\n",
      "308 has ratio 1:0, drop!\n",
      "307 has ratio 1:0, drop!\n",
      "305 has ratio 1:0, drop!\n",
      "637 has ratio 1:0, drop!\n",
      "304 has ratio 1:0, drop!\n",
      "325 has ratio 1:0, drop!\n",
      "374 has ratio 1:0, drop!\n",
      "389 has ratio 1:0, drop!\n",
      "388 has ratio 1:0, drop!\n",
      "380 has ratio 1:0, drop!\n",
      "392 has ratio 1:0, drop!\n",
      "393 has ratio 1:0, drop!\n",
      "685 has ratio 1:0, drop!\n",
      "377 has ratio 1:0, drop!\n",
      "387 has ratio 1:0, drop!\n",
      "480 has ratio 1:0, drop!\n",
      "383 has ratio 1:0, drop!\n",
      "391 has ratio 1:0, drop!\n",
      "379 has ratio 1:0, drop!\n",
      "378 has ratio 1:0, drop!\n",
      "385 has ratio 1:0, drop!\n",
      "384 has ratio 1:0, drop!\n",
      "386 has ratio 1:0, drop!\n",
      "390 has ratio 1:0, drop!\n",
      "394 has ratio 1:0, drop!\n",
      "279 has ratio 1:0, drop!\n",
      "89 has ratio 1:0, drop!\n",
      "91 has ratio 1:0, drop!\n",
      "92 has ratio 1:0, drop!\n",
      "94 has ratio 1:0, drop!\n",
      "101 has ratio 1:0, drop!\n",
      "95 has ratio 1:0, drop!\n",
      "97 has ratio 1:0, drop!\n",
      "98 has ratio 1:0, drop!\n",
      "99 has ratio 1:0, drop!\n",
      "498 has ratio 1:0, drop!\n",
      "100 has ratio 1:0, drop!\n",
      "86 has ratio 1:0, drop!\n",
      "84 has ratio 1:0, drop!\n",
      "81 has ratio 1:0, drop!\n",
      "79 has ratio 1:0, drop!\n",
      "78 has ratio 1:0, drop!\n",
      "75 has ratio 1:0, drop!\n",
      "74 has ratio 2:0, drop!\n",
      "93 has ratio 1:0, drop!\n",
      "128 has ratio 1:0, drop!\n",
      "124 has ratio 1:0, drop!\n",
      "126 has ratio 1:0, drop!\n",
      "127 has ratio 1:0, drop!\n",
      "129 has ratio 1:0, drop!\n",
      "136 has ratio 1:0, drop!\n",
      "131 has ratio 1:0, drop!\n",
      "132 has ratio 1:0, drop!\n",
      "133 has ratio 1:0, drop!\n",
      "134 has ratio 1:0, drop!\n",
      "135 has ratio 1:0, drop!\n",
      "120 has ratio 1:0, drop!\n",
      "117 has ratio 1:0, drop!\n",
      "116 has ratio 1:0, drop!\n",
      "114 has ratio 1:0, drop!\n",
      "113 has ratio 1:0, drop!\n",
      "112 has ratio 1:0, drop!\n",
      "111 has ratio 1:0, drop!\n",
      "664 has ratio 1:0, drop!\n",
      "110 has ratio 1:0, drop!\n",
      "105 has ratio 1:0, drop!\n",
      "594 has ratio 1:0, drop!\n",
      "67 has ratio 1:0, drop!\n",
      "30 has ratio 1:0, drop!\n",
      "29 has ratio 1:0, drop!\n",
      "589 has ratio 1:0, drop!\n",
      "27 has ratio 1:0, drop!\n",
      "26 has ratio 1:0, drop!\n",
      "25 has ratio 1:0, drop!\n",
      "23 has ratio 1:0, drop!\n",
      "22 has ratio 1:0, drop!\n",
      "21 has ratio 1:0, drop!\n",
      "20 has ratio 1:0, drop!\n",
      "14 has ratio 1:0, drop!\n",
      "12 has ratio 1:0, drop!\n",
      "777 has ratio 1:0, drop!\n",
      "10 has ratio 1:0, drop!\n",
      "9 has ratio 1:0, drop!\n",
      "5 has ratio 1:0, drop!\n",
      "4 has ratio 1:0, drop!\n",
      "3 has ratio 1:0, drop!\n",
      "2 has ratio 1:0, drop!\n",
      "1 has ratio 1:0, drop!\n",
      "724 has ratio 1:0, drop!\n",
      "15 has ratio 1:0, drop!\n",
      "699 has ratio 1:0, drop!\n",
      "32 has ratio 1:0, drop!\n",
      "34 has ratio 1:0, drop!\n",
      "55 has ratio 1:0, drop!\n",
      "59 has ratio 1:0, drop!\n",
      "60 has ratio 1:0, drop!\n",
      "715 has ratio 1:0, drop!\n",
      "344 has ratio 1:0, drop!\n",
      "714 has ratio 1:0, drop!\n",
      "62 has ratio 1:0, drop!\n",
      "709 has ratio 1:0, drop!\n",
      "63 has ratio 1:0, drop!\n",
      "64 has ratio 1:0, drop!\n",
      "51 has ratio 1:0, drop!\n",
      "47 has ratio 1:0, drop!\n",
      "46 has ratio 1:0, drop!\n",
      "43 has ratio 1:0, drop!\n",
      "41 has ratio 1:0, drop!\n",
      "743 has ratio 1:0, drop!\n",
      "40 has ratio 1:0, drop!\n",
      "39 has ratio 1:0, drop!\n",
      "38 has ratio 1:0, drop!\n",
      "37 has ratio 1:0, drop!\n",
      "35 has ratio 1:0, drop!\n",
      "138 has ratio 1:0, drop!\n",
      "241 has ratio 1:0, drop!\n",
      "139 has ratio 1:0, drop!\n",
      "227 has ratio 1:0, drop!\n",
      "229 has ratio 1:0, drop!\n",
      "230 has ratio 1:0, drop!\n",
      "231 has ratio 1:0, drop!\n",
      "233 has ratio 1:0, drop!\n",
      "240 has ratio 1:0, drop!\n",
      "479 has ratio 1:0, drop!\n",
      "234 has ratio 1:0, drop!\n",
      "235 has ratio 1:0, drop!\n",
      "236 has ratio 1:0, drop!\n",
      "237 has ratio 1:0, drop!\n",
      "797 has ratio 1:0, drop!\n",
      "463 has ratio 1:0, drop!\n",
      "408 has ratio 1:0, drop!\n",
      "221 has ratio 1:0, drop!\n",
      "340 has ratio 1:0, drop!\n",
      "341 has ratio 1:0, drop!\n",
      "783 has ratio 1:0, drop!\n",
      "212 has ratio 1:0, drop!\n",
      "211 has ratio 1:0, drop!\n",
      "210 has ratio 1:0, drop!\n",
      "209 has ratio 1:0, drop!\n",
      "232 has ratio 1:0, drop!\n",
      "776 has ratio 2:1, drop!\n",
      "243 has ratio 1:0, drop!\n",
      "263 has ratio 1:0, drop!\n",
      "264 has ratio 1:0, drop!\n",
      "553 has ratio 1:0, drop!\n",
      "268 has ratio 1:0, drop!\n",
      "275 has ratio 1:0, drop!\n",
      "269 has ratio 1:0, drop!\n",
      "270 has ratio 1:0, drop!\n",
      "271 has ratio 1:0, drop!\n",
      "272 has ratio 1:0, drop!\n",
      "273 has ratio 1:0, drop!\n",
      "274 has ratio 1:0, drop!\n",
      "258 has ratio 1:0, drop!\n",
      "90 has ratio 0:1, drop!\n",
      "395 has ratio 0:1, drop!\n",
      "276 has ratio 0:1, drop!\n",
      "44 has ratio 0:1, drop!\n",
      "250 has ratio 0:1, drop!\n",
      "337 has ratio 0:1, drop!\n",
      "249 has ratio 0:1, drop!\n",
      "248 has ratio 0:1, drop!\n",
      "262 has ratio 0:1, drop!\n",
      "328 has ratio 0:1, drop!\n",
      "247 has ratio 0:1, drop!\n",
      "96 has ratio 0:1, drop!\n",
      "430 has ratio 0:1, drop!\n",
      "245 has ratio 0:1, drop!\n",
      "333 has ratio 0:1, drop!\n",
      "223 has ratio 0:1, drop!\n",
      "19 has ratio 0:1, drop!\n",
      "206 has ratio 0:1, drop!\n",
      "197 has ratio 0:1, drop!\n",
      "376 has ratio 0:1, drop!\n",
      "169 has ratio 0:1, drop!\n",
      "168 has ratio 0:1, drop!\n",
      "346 has ratio 0:1, drop!\n",
      "636 has ratio 0:1, drop!\n",
      "115 has ratio 0:1, drop!\n",
      "156 has ratio 0:1, drop!\n",
      "76 has ratio 0:1, drop!\n",
      "61 has ratio 0:1, drop!\n",
      "338 has ratio 0:1, drop!\n",
      "336 has ratio 0:1, drop!\n",
      "514 has ratio 0:1, drop!\n",
      "512 has ratio 0:1, drop!\n",
      "151 has ratio 0:1, drop!\n",
      "150 has ratio 0:1, drop!\n",
      "149 has ratio 0:1, drop!\n",
      "146 has ratio 0:1, drop!\n",
      "301 has ratio 0:1, drop!\n",
      "144 has ratio 0:1, drop!\n",
      "143 has ratio 0:1, drop!\n",
      "142 has ratio 0:1, drop!\n",
      "141 has ratio 0:1, drop!\n",
      "154 has ratio 0:1, drop!\n",
      "172 has ratio 0:1, drop!\n",
      "173 has ratio 0:1, drop!\n",
      "345 has ratio 0:1, drop!\n",
      "88 has ratio 0:1, drop!\n",
      "195 has ratio 0:1, drop!\n",
      "205 has ratio 0:1, drop!\n",
      "242 has ratio 0:1, drop!\n",
      "202 has ratio 0:1, drop!\n",
      "203 has ratio 0:1, drop!\n",
      "342 has ratio 0:1, drop!\n",
      "204 has ratio 0:1, drop!\n",
      "723 has ratio 0:1, drop!\n",
      "522 has ratio 0:1, drop!\n",
      "181 has ratio 0:1, drop!\n",
      "770 has ratio 0:1, drop!\n",
      "178 has ratio 0:1, drop!\n",
      "36 has ratio 0:1, drop!\n",
      "332 has ratio 0:1, drop!\n",
      "174 has ratio 0:1, drop!\n",
      "228 has ratio 0:1, drop!\n",
      "292 has ratio 0:1, drop!\n",
      "let's generate final synteny table\n",
      "let's generate final synteny table\n",
      "let's generate final synteny table\n",
      "let's generate final synteny table\n",
      "let's generate final synteny table\n",
      "let's generate final synteny table\n"
     ]
    }
   ],
   "source": [
    "# step3 process drimm\n",
    "# from drimm-synteny, we get raw blocks, and we need to clean and sort the raw blcoks to\n",
    "## 1. split the all-in-one blocks (drimm-synteny output) into individual genomes\n",
    "## 2. meanwhile divide the blocks into separate ones based on ratio (normally from genome duplication, but segmental duplications cannot be distinguished, and are also processed)\n",
    "workdir = \"/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/workdir\"\n",
    "BED_folder = \"/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/\"\n",
    "if workdir[-1] != \"/\": workdir += \"/\"\n",
    "if BED_folder[-1] != \"/\": BED_folder += \"/\"\n",
    "\n",
    "outdir = workdir + \"out1/\"\n",
    "\n",
    "sp='sp46'\n",
    "index_file = \"/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/Smar.EM05.v1.genome.fa.fai\"\n",
    "df_index = make_index(sp,index_file) #your genome index and genome name you want to use\n",
    "DIC = {f\"{row['sp']}@{row['chr']}\": row['length'] for _, row in df_index.iterrows()}\n",
    "\n",
    "genome_meta = make_genome_meta(\"sp46\",1,17)\n",
    "chromosome_meta = make_chromosome_meta(BED_folder,DIC)\n",
    "\n",
    "#bed_path = \"/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/2_analysis/10_ancestralGenome/bed\"\n",
    "OG_type = \"synOG\" # synOG|orthofinder\n",
    "working_dir = outdir\n",
    "bed_dir = workdir + \"bed/\"\n",
    "\n",
    "if working_dir[-1] != \"/\": working_dir += \"/\"\n",
    "if bed_dir[-1] != \"/\": bed_dir += \"/\"\n",
    "\n",
    "target = [\"sp46\"]\n",
    "reference = \"sp03v5\"\n",
    "\n",
    "for species in target:\n",
    "    if not species == reference: \n",
    "        species_list = [reference, species]\n",
    "        sp_working_dir = working_dir + species + \"/\"\n",
    "        print(sp_working_dir)\n",
    "        homolog_dir = sp_working_dir + \"1_SynOG/\"\n",
    "        if not Path(sp_working_dir).exists():\n",
    "            print(\"no homologs found for \" + species)\n",
    "        else:\n",
    "            block_file = sp_working_dir + \"/2_DrimmRaw/blocks.txt\"\n",
    "            sequence = readSequence(block_file)\n",
    "            drimmSyntenyFile = sp_working_dir + \"/2_DrimmRaw/synteny.txt\"\n",
    "            \n",
    "            list_ = prepare_meta(species_list, genome_meta, chromosome_meta, OG_type, bed_dir)\n",
    "            sp_list = list_[0]\n",
    "            sp_ratio = list_[1]\n",
    "            sp_ratio = \":\".join([str(e) for e in sp_ratio]) # convert sp_ratio to a string\n",
    "            chr_number = list_[2]\n",
    "            \n",
    "            drimm_split_blocks_dir,raw_block_dir,result_dir = prepare_dir(sp_working_dir)\n",
    "            write_raw_blocks(sequence,chr_number,drimm_split_blocks_dir,sp_list)\n",
    "            processLCSAndFirstFilter = plff.processLCSAndFirstFilter(drimm_split_blocks_dir, raw_block_dir, sp_ratio,\n",
    "                                                         drimm_split_blocks_dir, homolog_dir, drimmSyntenyFile,\n",
    "                                                         sp_list, 's')\n",
    "            processLCSAndFirstFilter.excute()\n",
    "\n",
    "            processFinalFilter = pff.processFinalFilter(sp_list, raw_block_dir, drimm_split_blocks_dir, result_dir, 's')\n",
    "            processFinalFilter.excute()\n",
    "            shutil.rmtree(raw_block_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing sp03v5.bed\n",
      "processing sp46.bed\n",
      "processing sp03v5_2 blocks ...\n",
      "writing sp03v5_2 blocks ...\n",
      "sp03v5_2 done\n",
      "processing sp46_2 blocks ...\n",
      "writing sp46_2 blocks ...\n",
      "sp46_2 done\n",
      "processing sp46_1 blocks ...\n",
      "writing sp46_1 blocks ...\n",
      "sp46_1 done\n",
      "processing sp03v5_1 blocks ...\n",
      "writing sp03v5_1 blocks ...\n",
      "sp03v5_1 done\n",
      "processing sp46_3 blocks ...\n",
      "writing sp46_3 blocks ...\n",
      "sp46_3 done\n",
      "processing sp03v5_3 blocks ...\n",
      "writing sp03v5_3 blocks ...\n",
      "sp03v5_3 done\n"
     ]
    }
   ],
   "source": [
    "# use grimm2barplot to to do chromosome painting\n",
    "## use R packages chromoMap to paint blocks on full chromosme background (a difference to iage_plot function);\n",
    "## 2.1 let's first make a combed file based on normal bed, this special bed will be used by combed_parser() and grimmBlock_parser()\n",
    "beddir = BED_folder\n",
    "comBed = make_comBed(beddir)\n",
    "#comBed.to_csv(workdir + 'combBed.txt', sep='\\t', header=True, index=False)\n",
    "\n",
    "## 2.2 let's read in cleaned dirmm blocks, parse it and generate new data <5_SynBlocks>; no need to worry about ratio as all scenarios will be considered in one run\n",
    "working_dir = workdir + \"out1\"\n",
    "if not working_dir.endswith(\"/\"): working_dir += \"/\"\n",
    "\n",
    "target = [\"sp46\"]\n",
    "\n",
    "for species in target:\n",
    "    blockDir = working_dir + species + \"/3_DrimmBlocks/finalBlocks/\"\n",
    "    output_path = blockDir + \"../../5_SynBlocks/\"\n",
    "    if not os.path.exists(output_path): os.mkdir(output_path)\n",
    "    dic = combed_parser(comBed)\n",
    "    blockFiles = [os.path.join(blockDir, filename) for filename in os.listdir(blockDir) if filename.endswith('.synteny.genename')]\n",
    "    grimmBlock_parser(blockFiles,dic,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['670_1_chr_1', '672_1_chr_1', '671_1_chr_1', '669_1_chr_1', '667_1_chr_1', '519_1_chr_1', '523_1_chr_1', '528_1_chr_1', '526_1_chr_1', '765_1_chr_1', '510_1_chr_1', '418_1_chr_1', '422_1_chr_1', '423_1_chr_1', '426_1_chr_1', '433_1_chr_1', '651_1_chr_1', '432_1_chr_1', '431_1_chr_1', '429_1_chr_1', '653_1_chr_1', '411_1_chr_1']\n",
      "['632_1_chr_2', '603_1_chr_2', '631_1_chr_2', '663_1_chr_2', '662_1_chr_2', '534_1_chr_2', '561_1_chr_2', '564_1_chr_2', '567_1_chr_2', '660_1_chr_2', '794_1_chr_2', '605_1_chr_2', '680_1_chr_2', '600_1_chr_2', '555_1_chr_2', '778_1_chr_2', '486_1_chr_2', '467_1_chr_2', '551_1_chr_2', '541_1_chr_2', '547_1_chr_2', '538_1_chr_2', '543_1_chr_2', '545_1_chr_2', '539_1_chr_2', '549_1_chr_2', '602_1_chr_2', '505_1_chr_2', '494_1_chr_2', '502_1_chr_2', '491_1_chr_2', '487_1_chr_2']\n",
      "['535_1_chr_3', '533_1_chr_3', '506_1_chr_3', '503_1_chr_3', '532_1_chr_3', '501_1_chr_3', '499_1_chr_3', '781_1_chr_3', '434_1_chr_3', '530_1_chr_3', '425_1_chr_3', '427_1_chr_3', '607_1_chr_3', '609_1_chr_3', '784_1_chr_3', '629_1_chr_3', '620_1_chr_3', '621_1_chr_3', '622_1_chr_3', '624_1_chr_3', '626_1_chr_3', '428_1_chr_3', '722_1_chr_3', '721_1_chr_3', '595_1_chr_3', '703_1_chr_3', '614_1_chr_3', '616_1_chr_3', '618_1_chr_3', '628_1_chr_3']\n",
      "['562_1_chr_4', '745_1_chr_4', '483_1_chr_4', '617_1_chr_4', '658_1_chr_4', '702_1_chr_4', '413_1_chr_4', '648_1_chr_4', '654_1_chr_4', '437_1_chr_4', '652_1_chr_4', '645_1_chr_4', '642_1_chr_4', '646_1_chr_4', '650_1_chr_4', '563_1_chr_4', '565_1_chr_4', '566_1_chr_4', '568_1_chr_4']\n",
      "['537_1_chr_5', '799_1_chr_5', '557_1_chr_5', '560_1_chr_5', '785_1_chr_5', '577_1_chr_5', '575_1_chr_5', '573_1_chr_5', '576_1_chr_5', '572_1_chr_5', '570_1_chr_5', '596_1_chr_5', '592_1_chr_5', '593_1_chr_5', '590_1_chr_5', '800_1_chr_5', '587_1_chr_5', '599_1_chr_5', '719_1_chr_5', '606_1_chr_5', '597_1_chr_5']\n",
      "['731_1_chr_6', '746_1_chr_6', '744_1_chr_6', '649_1_chr_6', '773_1_chr_6', '655_1_chr_6', '643_1_chr_6', '647_1_chr_6', '639_1_chr_6', '641_1_chr_6', '640_1_chr_6', '679_1_chr_6', '638_1_chr_6', '769_1_chr_6', '657_1_chr_6', '405_1_chr_6', '674_1_chr_6', '439_1_chr_6', '438_1_chr_6', '410_1_chr_6', '412_1_chr_6', '525_1_chr_6']\n",
      "['489_1_chr_7', '496_1_chr_7', '527_1_chr_7', '524_1_chr_7', '520_1_chr_7', '517_1_chr_7', '682_1_chr_7', '515_1_chr_7', '683_1_chr_7', '688_1_chr_7', '692_1_chr_7', '465_1_chr_7', '468_1_chr_7', '469_1_chr_7', '466_1_chr_7', '471_1_chr_7', '720_1_chr_7', '729_1_chr_7', '751_1_chr_7', '627_1_chr_7', '713_1_chr_7']\n",
      "['612_1_chr_8', '399_1_chr_8', '403_1_chr_8', '404_1_chr_8', '400_1_chr_8', '406_1_chr_8', '401_1_chr_8', '611_1_chr_8', '407_1_chr_8', '681_1_chr_8', '474_1_chr_8', '634_1_chr_8', '464_1_chr_8', '460_1_chr_8', '402_1_chr_8']\n",
      "['727_1_chr_9', '756_1_chr_9', '759_1_chr_9', '732_1_chr_9', '739_1_chr_9', '742_1_chr_9', '734_1_chr_9', '761_1_chr_9', '753_1_chr_9', '484_1_chr_9', '550_1_chr_9', '548_1_chr_9', '544_1_chr_9', '540_1_chr_9', '558_1_chr_9', '554_1_chr_9', '697_1_chr_9', '689_1_chr_9', '693_1_chr_9']\n",
      "['580_1_chr_10', '581_1_chr_10', '582_1_chr_10', '584_1_chr_10', '706_1_chr_10', '687_1_chr_10', '726_1_chr_10', '735_1_chr_10', '585_1_chr_10', '583_1_chr_10', '711_1_chr_10', '701_1_chr_10', '747_1_chr_10', '718_1_chr_10', '796_1_chr_10', '704_1_chr_10', '749_1_chr_10', '758_1_chr_10', '710_1_chr_10', '552_1_chr_10', '454_1_chr_10', '559_1_chr_10', '457_1_chr_10', '698_1_chr_10', '737_1_chr_10']\n",
      "['694_1_chr_11', '696_1_chr_11', '755_1_chr_11', '760_1_chr_11', '754_1_chr_11', '752_1_chr_11', '750_1_chr_11', '762_1_chr_11', '542_1_chr_11', '571_1_chr_11', '574_1_chr_11', '578_1_chr_11', '485_1_chr_11']\n",
      "['625_1_chr_12', '780_1_chr_12', '623_1_chr_12', '615_1_chr_12', '588_1_chr_12', '608_1_chr_12', '601_1_chr_12', '789_1_chr_12', '421_1_chr_12', '436_1_chr_12', '417_1_chr_12', '396_1_chr_12', '419_1_chr_12', '420_1_chr_12', '397_1_chr_12', '416_1_chr_12', '415_1_chr_12', '659_1_chr_12', '673_1_chr_12', '678_1_chr_12', '666_1_chr_12', '656_1_chr_12', '675_1_chr_12', '644_1_chr_12']\n",
      "['531_1_chr_13', '740_1_chr_13', '717_1_chr_13', '684_1_chr_13', '741_1_chr_13', '686_1_chr_13', '691_1_chr_13', '707_1_chr_13', '716_1_chr_13', '705_1_chr_13', '712_1_chr_13', '700_1_chr_13', '775_1_chr_13', '738_1_chr_13', '733_1_chr_13']\n",
      "['521_1_chr_14', '516_1_chr_14', '766_1_chr_14', '518_1_chr_14', '513_1_chr_14', '511_1_chr_14', '492_1_chr_14', '490_1_chr_14', '529_1_chr_14', '509_1_chr_14', '488_1_chr_14', '493_1_chr_14', '495_1_chr_14', '497_1_chr_14', '507_1_chr_14']\n",
      "['586_1_chr_15', '661_1_chr_15', '793_1_chr_15', '604_1_chr_15', '591_1_chr_15', '424_1_chr_15', '556_1_chr_15', '805_1_chr_15', '546_1_chr_15', '569_1_chr_15', '677_1_chr_15', '668_1_chr_15', '500_1_chr_15', '782_1_chr_15']\n",
      "['690_1_chr_16', '473_1_chr_16', '695_1_chr_16', '613_1_chr_16', '708_1_chr_16', '757_1_chr_16', '748_1_chr_16', '728_1_chr_16', '725_1_chr_16', '459_1_chr_16', '446_1_chr_16', '449_1_chr_16', '451_1_chr_16', '453_1_chr_16', '456_1_chr_16', '458_1_chr_16', '619_1_chr_16', '730_1_chr_16']\n",
      "['435_1_chr_17', '610_1_chr_17', '475_1_chr_17', '444_1_chr_17', '791_1_chr_17', '443_1_chr_17', '462_1_chr_17', '482_1_chr_17', '442_1_chr_17', '477_1_chr_17', '461_1_chr_17', '440_1_chr_17', '470_1_chr_17', '476_1_chr_17', '472_1_chr_17', '448_1_chr_17', '478_1_chr_17', '447_1_chr_17', '450_1_chr_17', '452_1_chr_17', '445_1_chr_17', '441_1_chr_17']\n",
      "['511_1_chr_1', '513_1_chr_1', '516_1_chr_1', '766_1_chr_1', '518_1_chr_1', '521_1_chr_1', '529_1_chr_1', '509_1_chr_1', '488_1_chr_1', '490_1_chr_1', '492_1_chr_1', '493_1_chr_1', '495_1_chr_1', '497_1_chr_1', '507_1_chr_1']\n",
      "['499_1_chr_2', '501_1_chr_2', '503_1_chr_2', '506_1_chr_2', '532_1_chr_2', '533_1_chr_2', '535_1_chr_2']\n",
      "['562_1_chr_3', '563_1_chr_3', '565_1_chr_3', '566_1_chr_3', '568_1_chr_3']\n",
      "['570_1_chr_4', '572_1_chr_4', '573_1_chr_4', '575_1_chr_4', '576_1_chr_4', '577_1_chr_4', '785_1_chr_4', '560_1_chr_4', '799_1_chr_4', '557_1_chr_4', '537_1_chr_4']\n",
      "['540_1_chr_5', '544_1_chr_5', '548_1_chr_5', '550_1_chr_5', '554_1_chr_5', '558_1_chr_5', '484_1_chr_5']\n",
      "['418_1_chr_6', '422_1_chr_6', '423_1_chr_6', '426_1_chr_6', '429_1_chr_6', '431_1_chr_6', '432_1_chr_6', '433_1_chr_6', '411_1_chr_6']\n",
      "['402_1_chr_7', '460_1_chr_7', '464_1_chr_7', '470_1_chr_7', '476_1_chr_7', '478_1_chr_7', '472_1_chr_7', '448_1_chr_7', '441_1_chr_7', '445_1_chr_7', '447_1_chr_7', '450_1_chr_7', '452_1_chr_7']\n",
      "['584_1_chr_8', '552_1_chr_8', '583_1_chr_8', '585_1_chr_8', '735_1_chr_8', '758_1_chr_8', '747_1_chr_8', '749_1_chr_8', '726_1_chr_8', '687_1_chr_8', '711_1_chr_8', '706_1_chr_8', '710_1_chr_8', '796_1_chr_8', '718_1_chr_8', '704_1_chr_8', '701_1_chr_8']\n",
      "['689_1_chr_9', '693_1_chr_9', '697_1_chr_9', '753_1_chr_9', '756_1_chr_9', '759_1_chr_9', '761_1_chr_9', '727_1_chr_9', '732_1_chr_9', '734_1_chr_9', '739_1_chr_9', '742_1_chr_9']\n",
      "['632_1_chr_10']\n",
      "['615_1_chr_11', '780_1_chr_11', '623_1_chr_11', '625_1_chr_11', '608_1_chr_11', '588_1_chr_11', '789_1_chr_11', '601_1_chr_11', '659_1_chr_11', '666_1_chr_11', '673_1_chr_11', '675_1_chr_11', '678_1_chr_11', '656_1_chr_11', '644_1_chr_11']\n",
      "['642_1_chr_12', '646_1_chr_12', '650_1_chr_12', '654_1_chr_12', '648_1_chr_12', '658_1_chr_12', '617_1_chr_12', '745_1_chr_12', '702_1_chr_12', '483_1_chr_12', '413_1_chr_12', '424_1_chr_12', '805_1_chr_12', '556_1_chr_12', '546_1_chr_12', '782_1_chr_12', '569_1_chr_12', '500_1_chr_12']\n",
      "['489_1_chr_13', '496_1_chr_13', '527_1_chr_13', '524_1_chr_13', '520_1_chr_13', '517_1_chr_13', '682_1_chr_13', '515_1_chr_13']\n",
      "['519_1_chr_14', '523_1_chr_14', '526_1_chr_14', '765_1_chr_14', '528_1_chr_14', '510_1_chr_14']\n",
      "['487_1_chr_15', '491_1_chr_15', '494_1_chr_15', '502_1_chr_15', '505_1_chr_15', '534_1_chr_15', '561_1_chr_15', '564_1_chr_15', '567_1_chr_15']\n",
      "['571_1_chr_16', '574_1_chr_16', '578_1_chr_16', '542_1_chr_16', '485_1_chr_16']\n",
      "['525_1_chr_17', '412_1_chr_17', '410_1_chr_17', '405_1_chr_17', '438_1_chr_17', '439_1_chr_17']\n",
      "['454_1_chr_18', '457_1_chr_18', '737_1_chr_18', '698_1_chr_18']\n",
      "['757_1_chr_19', '708_1_chr_19', '720_1_chr_19', '690_1_chr_19', '695_1_chr_19', '713_1_chr_19', '751_1_chr_19', '729_1_chr_19', '613_1_chr_19', '627_1_chr_19']\n",
      "['586_1_chr_20', '591_1_chr_20', '793_1_chr_20', '604_1_chr_20', '661_1_chr_20', '668_1_chr_20', '677_1_chr_20']\n",
      "['645_1_chr_21', '652_1_chr_21', '437_1_chr_21']\n",
      "['653_1_chr_22', '651_1_chr_22']\n",
      "['649_1_chr_23', '773_1_chr_23', '655_1_chr_23', '643_1_chr_23', '647_1_chr_23', '641_1_chr_23', '640_1_chr_23', '639_1_chr_23', '638_1_chr_23', '769_1_chr_23', '679_1_chr_23', '657_1_chr_23', '674_1_chr_23']\n",
      "['672_1_chr_24', '671_1_chr_24', '670_1_chr_24', '669_1_chr_24', '667_1_chr_24']\n",
      "['794_1_chr_25', '663_1_chr_25', '662_1_chr_25', '660_1_chr_25']\n",
      "['634_1_chr_26']\n",
      "['680_1_chr_27', '631_1_chr_27', '605_1_chr_27', '603_1_chr_27', '602_1_chr_27', '600_1_chr_27']\n",
      "['599_1_chr_28', '597_1_chr_28', '606_1_chr_28', '596_1_chr_28', '593_1_chr_28', '592_1_chr_28', '590_1_chr_28', '800_1_chr_28', '587_1_chr_28']\n",
      "['595_1_chr_29', '607_1_chr_29', '784_1_chr_29', '609_1_chr_29', '629_1_chr_29', '628_1_chr_29', '626_1_chr_29', '624_1_chr_29', '622_1_chr_29', '621_1_chr_29', '620_1_chr_29', '618_1_chr_29', '616_1_chr_29', '614_1_chr_29']\n",
      "['612_1_chr_30', '611_1_chr_30', '610_1_chr_30', '681_1_chr_30']\n",
      "['684_1_chr_31', '741_1_chr_31', '740_1_chr_31', '738_1_chr_31', '733_1_chr_31']\n",
      "['731_1_chr_32', '746_1_chr_32', '744_1_chr_32']\n",
      "['755_1_chr_33', '760_1_chr_33', '762_1_chr_33', '754_1_chr_33', '752_1_chr_33', '750_1_chr_33', '696_1_chr_33', '694_1_chr_33']\n",
      "['692_1_chr_34', '688_1_chr_34', '683_1_chr_34']\n",
      "['703_1_chr_35', '722_1_chr_35', '721_1_chr_35', '719_1_chr_35']\n",
      "['531_1_chr_36', '717_1_chr_36', '712_1_chr_36', '775_1_chr_36', '705_1_chr_36', '700_1_chr_36', '707_1_chr_36', '716_1_chr_36', '686_1_chr_36', '691_1_chr_36']\n",
      "['725_1_chr_37', '748_1_chr_37', '728_1_chr_37', '730_1_chr_37', '619_1_chr_37', '458_1_chr_37', '456_1_chr_37', '453_1_chr_37', '451_1_chr_37', '459_1_chr_37', '449_1_chr_37', '446_1_chr_37']\n",
      "['444_1_chr_38', '443_1_chr_38', '442_1_chr_38', '440_1_chr_38', '461_1_chr_38', '462_1_chr_38', '482_1_chr_38', '791_1_chr_38', '477_1_chr_38', '475_1_chr_38', '474_1_chr_38']\n",
      "['473_1_chr_39', '471_1_chr_39', '469_1_chr_39', '468_1_chr_39', '466_1_chr_39', '465_1_chr_39']\n",
      "['436_1_chr_40', '396_1_chr_40', '397_1_chr_40']\n",
      "['407_1_chr_41', '401_1_chr_41', '406_1_chr_41', '404_1_chr_41', '400_1_chr_41', '399_1_chr_41', '403_1_chr_41', '435_1_chr_41']\n",
      "['781_1_chr_42', '428_1_chr_42', '427_1_chr_42', '425_1_chr_42', '530_1_chr_42', '434_1_chr_42']\n",
      "['421_1_chr_43', '420_1_chr_43', '419_1_chr_43', '417_1_chr_43', '416_1_chr_43', '415_1_chr_43']\n",
      "['467_1_chr_44', '486_1_chr_44', '778_1_chr_44', '551_1_chr_44', '549_1_chr_44', '547_1_chr_44', '545_1_chr_44', '543_1_chr_44', '541_1_chr_44', '539_1_chr_44', '538_1_chr_44', '555_1_chr_44']\n",
      "['559_1_chr_45', '582_1_chr_45', '581_1_chr_45', '580_1_chr_45']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "## 2.3 take outputs from last step, generate table for plotting in R package <chromoMap>; no need to worry about ratio as all scenarios will be considered in one run\n",
    "\n",
    "target = [\"sp46\"]\n",
    "reference = \"sp03v5\"\n",
    "working_dir = workdir + \"out1\"\n",
    "if not working_dir.endswith(\"/\"): working_dir += \"/\"\n",
    "\n",
    "for species in target:\n",
    "    blockDir = working_dir + species + \"/5_SynBlocks/\"\n",
    "    blocks = [file for file in os.listdir(blockDir) if file.endswith(\"synBlock.txt\")]\n",
    "    for block in blocks:\n",
    "        target_block_name = block.split(\"_\")[0]\n",
    "        target_block_type = block.split(\"_\")[1]\n",
    "        reference_block = blockDir + reference + \"_\" + target_block_type + \"_synBlock.txt\"\n",
    "        target_block = os.path.join(blockDir, block)\n",
    "        target_chr = blockDir + \"../3_DrimmBlocks/finalBlocks/\" + target_block_name + \"_\" + target_block_type +\".final.block\"\n",
    "        \n",
    "        dic1,dic2 = get_block_info(reference_block,target_block)\n",
    "        coo_gene,coo_bp = get_chromosome_info(target_chr,dic1,dic2)\n",
    "\n",
    "        columns = [\"chr\",\"haplotype\", \"start\", \"end\", \"ancestral_group\"]\n",
    "        output_path = blockDir + \"../6_chromPainting/\"\n",
    "        if not os.path.exists(output_path): os.mkdir(output_path)\n",
    "\n",
    "        r1 = pd.DataFrame(coo_gene, columns=columns) # make a dataframe from the list of list\n",
    "        r2 = pd.DataFrame(coo_bp, columns=columns) # make a dataframe from the list of list\n",
    "        out_put1 = output_path + target_block_name + \"_\" + target_block_type +\"_cooGene.txt\"\n",
    "        out_put2 = output_path + target_block_name + \"_\" + target_block_type +\"_cooBp.txt\"\n",
    "        r1.to_csv(out_put1, sep='\\t', header=True, index=False)\n",
    "        r2.to_csv(out_put2, sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.4 generate inputs for chromoMap\n",
    "sp='sp46'\n",
    "index_file = \"/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/Smar.EM05.v1.genome.fa.fai\"\n",
    "df_index = make_index(sp,index_file) #your genome index and genome name you want to use\n",
    "DIC = {f\"{row['sp']}@{row['chr']}\": row['length'] for _, row in df_index.iterrows()}\n",
    "\n",
    "genome_meta = make_genome_meta(\"sp46\",1,17)\n",
    "chromosome_meta = make_chromosome_meta(BED_folder,DIC)\n",
    "\n",
    "target = [\"sp46\"]\n",
    "\n",
    "workdir = \"/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/Asteraceae_phylogenomics/pipeline/workdir\"\n",
    "working_dir = workdir + \"/out1\"\n",
    "if working_dir[-1] != \"/\": working_dir += \"/\"\n",
    "\n",
    "# obtain information of chromosome number in all species from genome_meta\n",
    "#genome_meta_df = pd.read_csv(genome_meta, sep='\\t', dtype = str, keep_default_na=False, names=['genome', 'ratio1', 'ratio2','chromosome'])\n",
    "genome_meta_dict = genome_meta.set_index('sp')['chrN'].to_dict()\n",
    "chromosome_meta_dict = {lst[0]: lst[1:] for lst in chromosome_meta}\n",
    "\n",
    "for genome in target:\n",
    "    outdir = working_dir + genome + \"/\"\n",
    "    chromosome_list = chromosome_meta_dict[genome]\n",
    "    chr_info_list = []\n",
    "    i = 1\n",
    "    for chromosome in chromosome_list:\n",
    "        if i <= int(genome_meta_dict[genome]): # make sure only take the long chromosomes as specified in genome_meta\n",
    "            drimm_chr = \"chr_\" + chromosome.split(\"_\")[-2]\n",
    "            genome_chr = \"_\".join(chromosome.split(\"_\")[0:-2])\n",
    "            length = chromosome.split(\"_\")[-1]\n",
    "            chr_info = [drimm_chr,genome_chr,\"0\",length]\n",
    "            chr_info_list.append(chr_info)\n",
    "            i += 1\n",
    "    df = pd.DataFrame(chr_info_list, columns=['drimm_chr', 'genome_chr', 'start','end'])\n",
    "    df = df.sort_values(by='genome_chr')\n",
    "    df.to_csv(outdir+genome+\".txt\",sep=\"\\t\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
