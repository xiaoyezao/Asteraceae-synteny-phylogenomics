{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The pipeline to analyse Asteraceae genomes using Asteraceae synteny-phylogenomic framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACG (Asteraceae Comparative Genomics)\n",
    "#### The objective of this pipeline is to use the AGB framework (Asteraceae Genome Blocks defined in our paper[link]) to carry out comparative genomic study in the biggest Angiosperm family --Asteraceae\n",
    "1. Mapping asteraceae onto the 15*3 blocks\n",
    "2. Obtain the homologous gene groups in whcih we have syntenic genes, dispersed genes, tandem duplicated genes.\n",
    "3. Use the syntenic genes as anthors, we apply the graph-based syntenic blocks identification algorithm (drimm-synteny) to identify syntenic segments\n",
    "### before we start drimm-synteny anaslysis, we need to generate synOG table using genespace_parser()\n",
    "    refer to genespace_parser.ipynb\n",
    "    be carefull about how speciese name and gene name are connected (\"@\" or \"_\")\n",
    "1. use “processOrthofinder_tao.py” to process the genespace pangenome output to get “drimm.sequence” —> be careful about the copy_ratio\n",
    "\n",
    "2. use “drimm-synteny” on windows to built up drimm blocks. —→ this current only works on windows, we can use it on unix with Wine software, but on Merian, I have issues with X11 library which can not find by Wine\n",
    "\n",
    "3. use “processDrimm_tao.py” on the outputs from last step to obtain final blocks for IAGS\n",
    "\n",
    "4. use IAGS to construct ancestral genomes; I also tried mgra (by index and reformat the blocks) but it doesn’t work.\n",
    "    \n",
    "from here we can use either iags <option -ff> or grimm to calculate genome shuffling event’s:\n",
    "    \n",
    "5. ***a***) use “standardize_drimmBlocks.py” to index and reformat the drimm genomes including ancestors and also extent genomes; then use grimm to characterise genome rearrangements; ***b***) use iags to calculate directly\n",
    "\n",
    "6. plotting and interpretation using iags (option -p); before this we need use “processGenenumber_tao.py” to generate the data needed by iags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the source paths for the files\n",
    "riparianPath <- file.path(\"{genespaceDir}\", \"riparian\")\n",
    "pangenePath <- file.path(\"{genespaceDir}\", \"pangenes\")\n",
    "\n",
    "# List files with .pdf and _synOG.txt extensions\n",
    "riparian_files <- list.files(riparianPath, pattern = \"\\\\\\\\.pdf$\", full.names = TRUE)\n",
    "pangene_files <- list.files(pangenePath, pattern = \"_synOG\\\\\\\\.txt$\", full.names = TRUE)\n",
    "\n",
    "# Define the destination folder for macrosynteny\n",
    "macrosynteny <- file.path(\"{workDir}\", \"results\")\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "if (!dir.exists(macrosynteny)) {{\n",
    "    dir.create(macrosynteny, recursive = TRUE)\n",
    "}}\n",
    "\n",
    "# Check if both expected file types exist and copy them\n",
    "if (length(riparian_files) > 0 & length(pangene_files) > 0) {{\n",
    "    file.copy(riparian_files, macrosynteny, overwrite = TRUE)\n",
    "    file.copy(pangene_files, macrosynteny, overwrite = TRUE)\n",
    "    print(\"Files copied successfully!\")\n",
    "}} else {{\n",
    "    print(\"The riparian or pangene files don't exist, please check whether the Genespace run was successful...\")\n",
    "}}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dependencies ready\n",
    "import os,shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scripts.makeGenomeInfo as sGI\n",
    "import scripts.processDrimm as spd\n",
    "import scripts.processOG as spo\n",
    "import scripts.modules as m\n",
    "import scripts.configure as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize working environment\n",
    "packagedir = \"/home/feng041/scripts/ipynb/AGB_pipeline6/\"\n",
    "workdir = \"/home/feng041/project/1_asteraceae_phylogenomics/test_AGBpipeline/\"\n",
    "drimmPath = '/home/feng041//scripts/ipynb/AGB_pipeline6/software/DRIMM-Synteny'\n",
    "\n",
    "if not workdir[-1] == \"/\": workdir += \"/\"\n",
    "\n",
    "info = c.configure(workdir,packagedir)\n",
    "## info = (genespaceDir,resultsDir,meta,index,bedDir2,pepDir2)\n",
    "## this will check the depencies and the inputs, and make folders for outputs\n",
    "## this will also generate a R script \"run_genespace.R\" under your workDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "## as Running genespace will take some time, please run genespace outside this pipeline, for example in your terminal with correct conda environment:\n",
    "conda activate asteraceae_phylogenomics\n",
    "nohup R < run_genespace.R --no-save > nohup_genespace &\n",
    "# this will run genespace at background, if everything goes well, several files will be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run GENESPACE and get the results\n",
    "## we recommend to include the species and use ANC as an outgroup to get the best hirochcal OGs\n",
    "## namely prepare your genome data, pep and bed according to GENESPACE, put them in the corresponding folder, run Genespace\n",
    "##! currently, the chromosome name in AGB.bed is \"a1\", not \"a01\", while in the module makeGenomeInfo.make_index, the \"a01\" will be used, need to adjust this\n",
    "# get input data ready\n",
    "\n",
    "#info = (genespaceDir,resultsDir,meta,index,bedDir2,pepDir2)\n",
    "resultsDir = info[1]\n",
    "genome_meta = info[2]\n",
    "index_folder = info[3]\n",
    "bed_folder = info[4]\n",
    "pep_folder = info[5]\n",
    "\n",
    "pangenome = resultsDir + \"AGB_synOG.txt\"\n",
    "\n",
    "## let's first clean the pangenome table from Genespace;\n",
    "clean_pangenome = m.pangenome_cleaner(pangenome)\n",
    "## let's then parse the cleaned pangenome\n",
    "orthogroups = m.parse_pangenome(pangenome,clean_pangenome)\n",
    "# this is a tuble of the path to the outputs: *_all, *_syn, and *_synteny; *_syn will be used for the pipeline\n",
    "\n",
    "# Step 2. Get orthogroups ready\n",
    "ortho = pd.read_csv(orthogroups[1], sep='\\t', dtype = str, keep_default_na=False)\n",
    "ortho2 = ortho[ortho[\"interpChr\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. First, let's prepare inputs for the pipeline\n",
    "## make index file\n",
    "df_index = sGI.make_index(index_folder) #your genome index and genome name you want to use\n",
    "\n",
    "## make bed, genome_meta, chromosome_meta\n",
    "genomeMeta = sGI.make_genome_meta(genome_meta) # if you want to exclude some species, use '#' to annotate out this species\n",
    "#print(genomeMeta)\n",
    "chromosome_meta = sGI.make_chromosome_meta(bed_folder,DIC)\n",
    "#print(chromosome_meta)\n",
    "\n",
    "DIC = {f\"{row['sp']}@{row['chr']}\": row['length'] for _, row in df_index.iterrows()}\n",
    "bed_dir = resultsDir + \"drimmBED/\"\n",
    "if not os.path.exists(bed_dir):\n",
    "    os.makedirs(bed_dir)\n",
    "    sGI.make_drimmBED(bed_folder, DIC, bed_dir)\n",
    "else:\n",
    "    print(bed_dir + \" exists, let's generate bed file in this floder\")\n",
    "    sGI.make_drimmBED(bed_folder, DIC, bed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step2 perform drimm-synteny to call synteny blocks\n",
    "## process synOG table, call pairwise orthologs for given ref-target pair\n",
    "\n",
    "# for pairwise comparasion\n",
    "reference = \"AGB\"\n",
    "queries = genomeMeta['sp'].to_list()\n",
    "genome_meta_dict = genomeMeta.set_index('sp')['chrN'].to_dict()\n",
    "chromosome_meta_dict = {lst[0]: lst[1:] for lst in chromosome_meta}\n",
    "for species in queries:\n",
    "    if not species == reference:\n",
    "        species_list = [reference, species]\n",
    "        subdir = resultsDir + species + \"/1_SynOG/\" # 1. this is for two species, if we want to for multiple species, we need to change here\n",
    "        info_list = m.prepare_meta(species_list, genomeMeta, chromosome_meta)\n",
    "        sp,sp_ratio,sp_chr_number,long_chr_list,gff_list = info_list # this decides species pair\n",
    "        #print(info_list)\n",
    "        #print(sp)\n",
    "        #print(sp_chr_number)\n",
    "        # step 1, let's process cleaned pangene table to generate drimm.sequence for drimm-synteny\n",
    "        if not Path(subdir).exists():\n",
    "            os.makedirs(subdir)\n",
    "            # for genespace output\n",
    "            ortho3 = m.prepare_OG(ortho2,sp) # 2. here, the arguement 'sp' deciedes pair-wise or multiple-species comparasion\n",
    "            #print(ortho3)\n",
    "            '''\n",
    "            in prepare_OG() (modules.py line90) deals with ploidy genomes, namely in ortho2, there could be one/many to many\n",
    "            e.g. ref@Gene1   query@Gene1|query@Gene2\n",
    "            '''\n",
    "            group_dir = spo.get_group_dir(ortho3,sp) # 3. and here, the arguement 'sp' deciedes pair-wise or multiple-species comparasion \n",
    "            finalGroup = spo.get_final_group(group_dir,sp_ratio)\n",
    "            spo.processSynOG(bed_dir,subdir,group_dir,finalGroup,gff_list,long_chr_list)\n",
    "        else: print(\"SynOG for \" + species + \" exists, we will use this for Drimm-Synteny; If this is not correct, please delete 1_SynOG/ and rerun ...\")\n",
    "        \n",
    "        # step 2, let's process drimm.sequence to generate row drimm block\n",
    "        print(\"\\n=============================================================\\nlet's process orthologs to generate row blocks\\n=============================================================\\n)\n",
    "        drimmSequence = subdir + \"drimm.sequence\"\n",
    "        sp_ploidy = dict(zip(genomeMeta['sp'], genomeMeta['ploidy']))\n",
    "        dustThreshold = sp_ploidy[species] + sp_ploidy[reference] + 1\n",
    "        outPath = resultsDir + species + \"/2_DrimmRaw/\"\n",
    "        \n",
    "        if not Path(outPath).exists():\n",
    "            os.makedirs(outPath)\n",
    "            m.drimmSynteny(drimmSequence,drimmPath,outPath,dustThreshold)\n",
    "            print(\"drimm-synteny done!\")\n",
    "        else:\n",
    "            print(\"Drimm-Synteny outpath exists!!, we will check if blocks has been built ...\")\n",
    "            Block_File = outPath + \"blocks.txt\"\n",
    "            if Path(Block_File).exists() and Path(Block_File).stat().st_size > 0:\n",
    "                print(\"A block file seems has been generated, we will use this for next step; If this is not the correct, please delete the block file and rerun ...\")\n",
    "            else:\n",
    "                m.drimmSynteny(drimmSequence,drimmPath,outPath,dustThreshold)\n",
    "                print(\"drimm-synteny done!\")\n",
    "\n",
    "        \n",
    "        # step 3. let's process row drimm blocks to generate final blocks\n",
    "        print(\"\\n=============================================================\\nlet's process raw drimm blocks ...\\n=============================================================\\n\")\n",
    "        spd.main(info_list,species,resultsDir)\n",
    "        \n",
    "        print(\"\\n=============================================================\\nlet's generate cleaned blocks ...\\n=============================================================\\n\")\n",
    "        ## let's first make a combed file based on normal bed, this special bed will be used by combed_parser() and grimmBlock_parser()\n",
    "        comBed = m.make_comBed(bed_folder)\n",
    "        m.synBlock(resultsDir, species, comBed)\n",
    "        \n",
    "        print(\"\\n=============================================================\\nlet's generate data for chromosome painting ...\\n=============================================================\\n\")\n",
    "        m.chroBlock(resultsDir, species, reference, chromosome_meta_dict, genome_meta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chracterize genome rearrangements\n",
    "# there are two options:\n",
    "## 1. iags approach (fission, fusion), please follow iags guide; the output from step 3 can be used directly\n",
    "### 1.1 to wrapper iags\n",
    "\n",
    "## 2. Grimm approach (fission, fusion, inversion, translocation); \n",
    "### 2.1 to use grimm, we need to manipulate the data to fit grimm; this will generate grimm format genome <4_GrimmBlocks>;\n",
    "### 2.2 be careful with the parameter <ratio> which aims to handle duplicated blocks and single blocks independently\n",
    "\n",
    "'''\n",
    "the drimm format genomes (finalBlocks) from processDrimm use geneIDs that not started from 1, which is not like by grimm and mgra\n",
    "here, we re-code the geneID from 1 to x\n",
    "'''\n",
    "drimm_genome_path = \"/Users/fengtao/Library/CloudStorage/OneDrive-WageningenUniversity&Research/project/Asteraceae_evolution/2_analysis/10_ancestralGenome/genespace26/refSp03v1\"\n",
    "#drimm_ancestor_genome_path = \"/Users/fengtao/Library/Group Containers/G69SCX94XU.duck/Library/Application Support/duck/Volumes.noindex/myers/project/1_asteraceae_phylogenomics/4_ancestralGenome/iags\"\n",
    "#drimm_genomes_new = \"/Users/fengtao/Library/Group Containers/G69SCX94XU.duck/Library/Application Support/duck/Volumes.noindex/myers/project/1_asteraceae_phylogenomics/4_ancestralGenome/extent_indexed.drimm\"\n",
    "#list = [\"sp03v1\",\"sp03v5\",\"sp15\",\"sp07\",\"sp03\",\"sp41\",\"sp13\",\"sp11\",\"sp29\",\"sp30\",\"sp22\",\"sp21\",\"sp14\",\"sp10\",\"sp08\",\"sp35\"]\n",
    "list = [\"sp03v1\",\"sp03\",\"sp07\",\"sp10\",\"sp13\",\"sp15\",\"sp21\",\"sp29\",\"sp35\",\"sp03v5\",\"sp08\",\"sp11\",\"sp14\",\"sp18\",\"sp22\",\"sp30\",\"sp41\"] # be carefully, the referrence genome needs to be in the list\n",
    "ratio = 2 # the ratio of blocks between target and query genomes\n",
    "genome_list = [genome + \"_\" + str(ratio) for genome in list]\n",
    "print(genome_list)\n",
    "\n",
    "# to gather the genomes we want to include, sometimes we want only analysis some geneomes, for example drimm consider ancestor to descent, mgra takes only extant genomes\n",
    "if not drimm_genome_path[-1] == \"/\": drimm_genome_path += \"/\"\n",
    "for file in os.listdir(drimm_genome_path):\n",
    "    print(file)\n",
    "    genome_path = []\n",
    "    if file in list:\n",
    "        path = drimm_genome_path + file + \"/3_DrimmBlocks/finalBlocks/\"\n",
    "        if not os.path.exists(drimm_genome_path + file + \"/4_GrimmBlocks\"): os.mkdir(drimm_genome_path + file + \"/4_GrimmBlocks\")\n",
    "        grimmBlocks = drimm_genome_path + file + \"/4_GrimmBlocks/grimm_\" + str(ratio) + \".block\"\n",
    "        for file2 in os.listdir(path):\n",
    "            if file2.endswith(\"_\" + str(ratio) + \".final.block\"):\n",
    "                genome_path.append(path + file2)\n",
    "        print(genome_path)\n",
    "        standarlize_drimmblocks(genome_list, genome_path, grimmBlocks)\n",
    "\n",
    "### 2.3 go to grimm to calculate genome shufflings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asteraceae_SynPhylo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
